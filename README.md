# Opti-Q: A Constraint-Based Optimization Framework for Multi-LLM Question Planning

This repository contains the implementation and experimental scripts for the paper:

> **Opti-Q: A Constraint-Based Optimization Framework for Multi-LLM Question Planning **  


---

## ğŸ“˜ Overview

**Opti-Q** introduces a multi-objective optimization framework that plans and executes Large Language Model (LLM) questions under cost, latency, and energy constraints while maximizing **Quality of Answer (QoA)**.  
The system uses the **NSGA-II genetic algorithm** to find Pareto-optimal execution plans for question-answering workflows.

---

## ğŸ§© Repository Structure

```
OptiQ/
â”‚
â”œâ”€â”€ nsga/
â”‚   â”œâ”€â”€ gnsaga.py                 # Core NSGA-II implementation
â”‚   â”œâ”€â”€ utils_cost_qoa.py         # Cost and QoA calculation scripts
â”‚   â”œâ”€â”€ perf_eval.py              # Performance normalization and Pareto analysis
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp_levels/               # PerfDB level experiments (0â€“4)
â”‚   â”œâ”€â”€ exp_operations/           # Impact of max operation count (K=1â€“5)
â”‚   â”œâ”€â”€ exp_budgets/              # Budget-constrained runs (financial/latency)
â”‚   â”œâ”€â”€ exp_importance/           # LLM importance and weighting experiments
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_nsga_server.sh        # Bash script to run experiments on server/SLURM
â”‚   â”œâ”€â”€ collect_results.sh        # Script to aggregate experiment outputs
â”‚   â”œâ”€â”€ preprocess_perfdb.py      # Preprocessing for performance database
â”‚   â”œâ”€â”€ analyze_results.ipynb     # Post-experiment plots and analysis
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ perfdb.csv                # Historical performance metadata (sample)
â”‚   â”œâ”€â”€ results/                  # Output files from NSGA-II runs
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ metrics_boxplots.png
â”‚   â”œâ”€â”€ pareto_fronts.png
â”‚   â”œâ”€â”€ level_analysis.png
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## âš™ï¸ Experiments Included

| Experiment | Description |
|-------------|-------------|
| **Level Experiments (0â€“4)** | Tests planner adaptability with increasing PerfDB historical coverage. |
| **Max Operations (K)** | Evaluates how the number of operations affects expressiveness and efficiency. |
| **Budget Constraints** | Sweeps over financial and latency limits to study trade-offs. |
| **LLM Importance** | Measures contribution and sensitivity of individual LLMs to Pareto fronts. |

Each experiment reports **QoA, Cost, Latency, and Energy** with **95% confidence intervals** over multiple runs.

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Local or SLURM Execution
```bash

```

### 2ï¸âƒ£ Collect Results
```bash

```


---

## ğŸ§® Core Components

| File | Function |
|------|-----------|
| `gnsaga.py` | NSGA-II algorithm implementation (elitism, crossover, mutation) |
| `utils_cost_qoa.py` | Cost and QoA computation functions |
| `perf_eval.py` | Normalization, Pareto front extraction, CI calculation |
| `run_nsga_server.sh` | SLURM-compatible script for running experiments |
| `collect_results.sh` | Collects and merges distributed result files |

---

## ğŸ“Š Metrics

| Metric | Description |
|---------|-------------|
| **QoA** | Quality of Answer (using Mini-LV6 or exact match) |
| **Cost** | Model invocation cost (USD Ã— 10â»â´ scale) |
| **Latency** | Execution time in seconds |
| **Energy** | Estimated consumption (Joules) |

---

## ğŸ§  Methodology

The framework optimizes four competing objectives using **NSGA-II**:
1. Maximize QoA  
2. Minimize Cost  
3. Minimize Latency  
4. Minimize Energy  

Each population represents a multi-LLM execution plan, and evolution proceeds via crossover, mutation, and Pareto dominance sorting.

---

## ğŸ§° Requirements

- Python â‰¥ 3.9  
- NumPy  
- Pandas  
- Matplotlib  
- SciPy  
- tqdm  
- jsonlines  

Install all dependencies:
```bash
pip install -r requirements.txt
```
---

## ğŸ“œ License

Released under the **MIT License**.  
See the [LICENSE](LICENSE) file for full details.

---

